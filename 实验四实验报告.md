# 实验四

#### 171098064 马小堤

### 1. Spark环境配置

实验所用系统为macOS 10.15.7。首先通过Homebrew下载安装scala。

```shell
brew install scala
```

`vim ~/.bash_profile`配置scala环境变量。

```shell
export SCALA_HOME=/usr/local/Cellar/scala/2.13.4/libexec
export PATH=$PATH:$SCALA_HOME/bin
```

执行 `scala -version`，验证scala安装成功。

<img src="/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201215140500984.png" alt="image-20201215140500984" style="zoom:50%;" />

通过Homebrew下载安装Spark。

```shell
brew install apache-spark
```

`vim ~/.bash_profile`配置spark环境变量。

```shell
export SPARK_HOME=/usr/local/Cellar/apache-spark/3.0.1/libexec
export PATH=$PATH:$SPARK_HOME/bin
```

进入spark安装路径下`/conf`文件夹，由于该目录下只有spark-env.sh.template和slaves.template文件，因此进行拷贝和重命名。

```shell
cp spark-env.sh.template spark-env.sh
cp slaves.template slaves
```

编辑spark-env.sh，添加如下内容：

```shell
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home
export SCALA_HOME=/usr/local/Cellar/scala/2.13.4/libexec
export SPARK_MASTER_HOST=localhost
export SPARK_MASTER_PORT=7077
```

在 `/sbin`目录下执行 `./start-all.sh`（避免和之前安装的hadoop产生冲突），随后运行 `jps`查看当前进程。

<img src="/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201215144334436.png" alt="image-20201215144334436" style="zoom:50%;" />

有Worker和Master节点，则spark启动成功。进入web界面 `locahost:8080`：

![image-20201215144630595](/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201215144630595.png)

则spark伪分布式配置成功。

### 2. 任务一：分别编写mapreduce和spark应用程序统计双十一最热门的商品和最受年轻人关注的商家

创建名为Task1的java应用项目。

```shell
mvn archetype:generate "-DgroupId=t1" "-DartifactId=Task1" "-DarchetypeArtifactId=maven-archetype-quickstart" "-DinteractiveMode=false"  
```

