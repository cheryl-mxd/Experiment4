# 实验四

#### 171098064 马小堤

### 1. Spark环境配置

实验所用系统为macOS 10.15.7。首先通过Homebrew下载安装scala。

```shell
brew install scala
```

`vim ~/.bash_profile`配置scala环境变量。

```shell
export SCALA_HOME=/usr/local/Cellar/scala/2.13.4/libexec
export PATH=$PATH:$SCALA_HOME/bin
```

执行 `scala -version`，验证scala安装成功。

<img src="/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201215140500984.png" alt="image-20201215140500984" style="zoom:50%;" />

通过Homebrew下载安装Spark。

```shell
brew install apache-spark
```

`vim ~/.bash_profile`配置spark环境变量。

```shell
export SPARK_HOME=/usr/local/Cellar/apache-spark/3.0.1/libexec
export PATH=$PATH:$SPARK_HOME/bin
```

进入spark安装路径下`/conf`文件夹，由于该目录下只有spark-env.sh.template和slaves.template文件，因此进行拷贝和重命名。

```shell
cp spark-env.sh.template spark-env.sh
cp slaves.template slaves
```

编辑spark-env.sh，添加如下内容：

```shell
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home
export SCALA_HOME=/usr/local/Cellar/scala/2.13.4/libexec
export SPARK_MASTER_HOST=localhost
export SPARK_MASTER_PORT=7077
```

在 `/sbin`目录下执行 `./start-all.sh`（避免和之前安装的hadoop产生冲突），随后运行 `jps`查看当前进程。

<img src="/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201215144334436.png" alt="image-20201215144334436" style="zoom:50%;" />

有Worker和Master节点，则spark启动成功。进入web界面 `locahost:8080`：

![image-20201215144630595](/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201215144630595.png)

则spark伪分布式配置成功。

### 2. 任务一：分别编写mapreduce和spark应用程序统计双十一最热门的商品和最受年轻人关注的商家

#### 2.1 MapReduce统计程序

创建名为Task1的java应用项目。

```shell
mvn archetype:generate "-DgroupId=t1" "-DartifactId=Task1" "-DarchetypeArtifactId=maven-archetype-quickstart" "-DinteractiveMode=false"  
```

与WordCount的思路类似，实现两个MapReduce job。

第一个job（GoodsMapper+GoodsReducer）实现最热门商品的统计。map函数中读取用户行为日志，通过设置每一行拆分出的字符串数组长度作为条件过滤掉含有缺失值的行，同时剔除action_type=0的仅单击数据，将（item_id, 1）键值对传入reducer进行统计。Reducer中通过cleanup()函数，将reduce()输出的结果降序排序，并输出前100名。

第二个job（MerchantsMapper+MerchantsReducer）实现最受年轻人关注商家的统计。Mapper中在setup()函数里读取用户画像数据，筛选出30岁以下的user_id，map函数中匹配包含这部分user_id的数据，将（merchant_id, 1）键值对传入reducer进行统计。Reducer中同样通过cleanup()函数将结果排序并部分输出。

#### 2.2 Spark统计程序

同样利用maven新建一个项目，由于需要使用scala，因此在IDEA里配置project structure中的global libraries，加入scala jdk。此处需要注意的是scala的最新版本为2.13.4，然而maven repository中对应spark 3.0.1版本的scala为2.12版本，因此需要重新browse搜索2.12版本的scala jdk并配置到项目中，否则运行会报错。

将 `src/main`目录下的java文件夹重命名为scala，在package st1中新建一个scala class，名称为Count，类型为Object。

### 3. 任务二：编写Spark程序统计双十一购买了商品的男女比例，以及购买了商品的买家年龄段的比例

<img src="/Users/sheddy_ma/Library/Application Support/typora-user-images/image-20201229031740219.png" alt="image-20201229031740219" style="zoom:50%;" />
